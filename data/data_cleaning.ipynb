{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16835/3485441259.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_16835/3485441259.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: re.sub(r\"[^\\x20-\\x7E]\", \" \", x) if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv(\"works.csv\")\n",
    "\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# keep only printable characters\n",
    "df = df.applymap(lambda x: re.sub(r\"[^\\x20-\\x7E]\", \" \", x) if isinstance(x, str) else x)\n",
    "\n",
    "df = df.replace(r'^\\s*$', None, regex=True)\n",
    "\n",
    "# clean DOIs (remove URL prefixes and spaces)\n",
    "def clean_doi(doi):\n",
    "    if not isinstance(doi, str):\n",
    "        return None\n",
    "    doi = doi.strip().lower()\n",
    "    doi = re.sub(r'https?://(dx\\.)?doi\\.org/', '', doi)\n",
    "    doi = doi.split(' ')[0]\n",
    "    return doi or None\n",
    "\n",
    "df[\"doi\"] = df[\"doi\"].apply(clean_doi)\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"doi\", \"title\"])\n",
    "\n",
    "df.to_csv(\"works_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6536, 11)\n",
      "\n",
      "Columns: ['orgunit', 'title', 'pub_type', 'date_issued', 'authors', 'doi', 'publisher', 'abstract_en', 'abstract_de', 'pdf_paths', 'pdf_count']\n",
      "\n",
      "Sample rows:\n",
      "          orgunit                                              title  \\\n",
      "0            E194  Unplugged Decision Tree Learning   A Learning ...   \n",
      "1  E194;E235;E105  Opportunities and pitfalls of regression algor...   \n",
      "\n",
      "        pub_type date_issued  \\\n",
      "0  Inproceedings        2025   \n",
      "1        Article  2025-02-01   \n",
      "\n",
      "                                             authors  \\\n",
      "0                     Lehner, Lukas,Landman, Martina   \n",
      "1  Huymajer, Marco,Filzmoser, Peter,Mazak, Alexan...   \n",
      "\n",
      "                              doi                    publisher  \\\n",
      "0     10.1007/978-3-031-73257-7_4  Springer Nature Switzerland   \n",
      "1  10.1016/j.engappai.2024.109599                          NaN   \n",
      "\n",
      "                                         abstract_en abstract_de pdf_paths  \\\n",
      "0  Artificial intelligence (AI) is now deeply ing...         NaN       NaN   \n",
      "1  The residual value of heavy equipment is essen...         NaN       NaN   \n",
      "\n",
      "   pdf_count  \n",
      "0          0  \n",
      "1          0  \n",
      "\n",
      "Missing DOIs: 2105\n",
      "Missing abstracts (EN): 2036\n",
      "Missing titles: 0\n",
      "\n",
      "Example title sample:\n",
      "- Communication interface specification in OPC UA\n",
      "- Big Data Semantics\n",
      "- Hardware and Software Architectures for Energy-Efficient Smart Healthcare System\n"
     ]
    }
   ],
   "source": [
    "df_c = pd.read_csv(\"works_clean.csv\")\n",
    "\n",
    "print(\"Shape:\", df_c.shape)\n",
    "print(\"\\nColumns:\", df_c.columns.tolist())\n",
    "print(\"\\nSample rows:\")\n",
    "print(df_c.head(2))\n",
    "\n",
    "print(\"\\nMissing DOIs:\", df_c['doi'].isna().sum())\n",
    "print(\"Missing abstracts (EN):\", df_c['abstract_en'].isna().sum())\n",
    "print(\"Missing titles:\", df_c['title'].isna().sum())\n",
    "\n",
    "#text check\n",
    "print(\"\\nExample title sample:\")\n",
    "for t in df_c['title'].dropna().sample(min(3, len(df_c)), random_state=1):\n",
    "    print(\"-\", t[:80])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 / 6536 DOIs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m DOIs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     33\u001b[0m meta_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(metadata_records)\n\u001b[1;32m     34\u001b[0m df_enriched \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, meta_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def fetch_openalex_metadata(doi):\n",
    "    if not isinstance(doi, str) or not doi:\n",
    "        return None\n",
    "    url = f\"https://api.openalex.org/works/https://doi.org/{doi}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        data = r.json()\n",
    "        return {\n",
    "            \"openalex_id\": data.get(\"id\"),\n",
    "            \"concepts\": [c[\"display_name\"] for c in data.get(\"concepts\", [])],\n",
    "            \"cited_by_count\": data.get(\"cited_by_count\"),\n",
    "            \"referenced_works_count\": len(data.get(\"referenced_works\", []))\n",
    "        }\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "metadata_records = []\n",
    "for i, doi in enumerate(df[\"doi\"]):\n",
    "    if pd.isna(doi):\n",
    "        metadata_records.append({})\n",
    "        continue\n",
    "    meta = fetch_openalex_metadata(doi)\n",
    "    metadata_records.append(meta or {})\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Processed {i} / {len(df)} DOIs\")\n",
    "    time.sleep(0.5)  \n",
    "\n",
    "meta_df = pd.DataFrame(metadata_records)\n",
    "df_enriched = pd.concat([df, meta_df], axis=1)\n",
    "\n",
    "df_enriched.to_csv(\"works_enriched.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6683, 15)\n",
      "\n",
      "New columns: ['openalex_id', 'concepts', 'cited_by_count', 'referenced_works_count']\n",
      "\n",
      "Sample enriched rows:\n",
      "                                                                                                                                   title                            doi                                                                                                                                                                                                                                                                                                                       concepts  cited_by_count  referenced_works_count\n",
      "                                           Unplugged Decision Tree Learning   A Learning Activity for Machine Learning Education in K-12    10.1007/978-3-031-73257-7_4                                                                                                                                                    ['Computer science', 'Decision tree', 'Artificial intelligence', 'Machine learning', 'Decision tree learning', 'Tree (set theory)', 'Mathematics', 'Mathematical analysis']             2.0                    10.0\n",
      "       Opportunities and pitfalls of regression algorithms for predicting the residual value of heavy equipment   A comparative analysis 10.1016/j.engappai.2024.109599                                                                                                                                                      ['Computer science', 'Residual', 'Regression', 'Value (mathematics)', 'Algorithm', 'Regression analysis', 'Data mining', 'Machine learning', 'Statistics', 'Mathematics']             0.0                    44.0\n",
      "                                                                                         SPiKE: 3D Human Pose from Point Cloud Sequences   10.1007/978-3-031-78456-9_30                                                                                                ['Computer science', 'Point cloud', 'Spike (software development)', 'Artificial intelligence', 'Computer vision', 'Point (geometry)', 'Cloud computing', 'Geometry', 'Mathematics', 'Operating system', 'Software engineering']             2.0                    41.0\n",
      "                                            Quality Metrics and Reordering Strategies for Revealing Patterns in BioFabric Visualizations      10.1109/tvcg.2024.3456312                                                                                                                                                                                               ['Computer science', 'Visualization', 'Quality (philosophy)', 'Data visualization', 'Data mining', 'Philosophy', 'Epistemology']             2.0                    49.0\n",
      "                          Digitaler Plattform- und Systembau:  ber Spezifika, Evolution und IT-Architekturen in Sport und Rehabilitation 10.1007/978-3-662-68241-8_23-1                                                                                                                                                                                                                                                                                                           ['Computer science']             0.0                    34.0\n",
      "SHARP: Segmentation of Hands and Arms by Range Using Pseudo-depth for Enhanced Egocentric 3D Hand Pose Estimation and Action Recognition   10.1007/978-3-031-78354-8_12                                  ['Computer science', 'Artificial intelligence', 'Computer vision', 'Segmentation', 'Pose', 'Range (aeronautics)', 'Action (physics)', 'Action recognition', 'Pattern recognition (psychology)', 'Engineering', 'Aerospace engineering', 'Physics', 'Quantum mechanics', 'Class (philosophy)']             1.0                    28.0\n",
      "                                                                                               Large and Parallel Human Sorting Networks   10.1007/978-3-031-73257-7_16                                                                                                                                                                                                                     ['Computer science', 'Sorting', 'Parallel computing', 'Sorting network', 'Sorting algorithm', 'Algorithm']             0.0                     7.0\n",
      "                                        UnDRground Tubes: Exploring Spatial Data With Multidimensional Projections and Set Visualization      10.1109/tvcg.2024.3456314 ['Computer science', 'Visualization', 'Data visualization', 'Data set', 'Geovisualization', 'Set (abstract data type)', 'Multidimensional data', 'Spatial analysis', 'Computer graphics (images)', 'Data mining', 'Information visualization', 'Artificial intelligence', 'Geology', 'Remote sensing', 'Programming language']             1.0                    62.0\n",
      "                                                                     KaiRacters: Character-Level-Based Writer Retrieval for Greek Papyri    10.1007/978-3-031-78495-8_5                                                                                                                                                                  ['Character (mathematics)', 'Computer science', 'Natural language processing', 'Artificial intelligence', 'Information retrieval', 'Mathematics', 'Geometry']             2.0                    22.0\n",
      "                                                    On the Generalization of WiFi-Based Person-Centric Sensing in Through-Wall Scenarios   10.1007/978-3-031-78354-8_13                                                                                                                                                                                        ['Computer science', 'Generalization', 'Artificial intelligence', 'Humanâ€“computer interaction', 'Mathematics', 'Mathematical analysis']             0.0                    26.0\n",
      "\n",
      "Enriched entries count: 4256\n",
      "Missing OpenAlex IDs: 2427\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"works_enriched.csv\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nNew columns:\", [c for c in df.columns if c in ['openalex_id', 'concepts', 'cited_by_count', 'referenced_works_count']])\n",
    "\n",
    "sample = df[df['openalex_id'].notna()].head(10)[\n",
    "    ['title', 'doi', 'concepts', 'cited_by_count', 'referenced_works_count']\n",
    "]\n",
    "print(\"\\nSample enriched rows:\")\n",
    "print(sample.to_string(index=False))\n",
    "\n",
    "print(\"\\nEnriched entries count:\", df['openalex_id'].notna().sum())\n",
    "print(\"Missing OpenAlex IDs:\", df['openalex_id'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"works_enriched.csv\")\n",
    "\n",
    "# normalize concepts\n",
    "def normalize_concepts(val):\n",
    "    if pd.isna(val):\n",
    "        return \"\"\n",
    "    try:\n",
    "        items = ast.literal_eval(val) if isinstance(val, str) and val.startswith('[') else val.split(';')\n",
    "        items = [x.strip().lower() for x in items if isinstance(x, str)]\n",
    "        return \"; \".join(sorted(set(items)))\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "df[\"concepts_norm\"] = df[\"concepts\"].apply(normalize_concepts)\n",
    "\n",
    "# clean abstracts\n",
    "df[\"abstract_en\"] = df[\"abstract_en\"].fillna(\"\").str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "df[\"title\"] = df[\"title\"].fillna(\"\").str.strip()\n",
    "\n",
    "df_ready = df[(df[\"abstract_en\"].str.len() > 50) | (df[\"concepts_norm\"].str.len() > 0)]\n",
    "\n",
    "df_ready.to_csv(\"works_ready.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5814, 16)\n",
      "\n",
      "Columns: ['orgunit', 'title', 'pub_type', 'date_issued', 'authors', 'doi', 'publisher', 'abstract_en', 'abstract_de', 'pdf_paths', 'pdf_count', 'openalex_id', 'concepts', 'cited_by_count', 'referenced_works_count', 'concepts_norm']\n",
      "\n",
      "Missing abstracts: 1314\n",
      "Missing concepts: 1583\n",
      "Missing DOIs: 1699\n",
      "\n",
      "Sample entries:\n",
      "                                               title  \\\n",
      "0  Unplugged Decision Tree Learning   A Learning ...   \n",
      "1  Opportunities and pitfalls of regression algor...   \n",
      "2    SPiKE: 3D Human Pose from Point Cloud Sequences   \n",
      "\n",
      "                                            concepts  \\\n",
      "0  ['Computer science', 'Decision tree', 'Artific...   \n",
      "1  ['Computer science', 'Residual', 'Regression',...   \n",
      "2  ['Computer science', 'Point cloud', 'Spike (so...   \n",
      "\n",
      "                                         abstract_en  \n",
      "0  Artificial intelligence (AI) is now deeply ing...  \n",
      "1  The residual value of heavy equipment is essen...  \n",
      "2                                                NaN  \n",
      "\n",
      "Usable entries: 5814 / 5814 (100.0%)\n",
      "\n",
      "Sample concept lists:\n",
      "- ['Injective function', 'Resolution (logic)', 'Homomorphism', 'Mathematical proof', 'Computer science', 'Dependency (UML)', 'Exploit', 'Homogeneous space', 'Theoretical computer science', 'Discrete mathematics', 'Algorithm', 'Algebra over a field', 'Mathematics', 'Pure mathematics', 'Artificial intelligence', 'Computer security', 'Geometry']\n",
      "- ['Treewidth', 'Parameterized complexity', 'Mathematics', 'Combinatorics', 'Maximum cut', 'Tree decomposition', 'Bounded function', 'Vertex cover', 'Steiner tree problem', 'Discrete mathematics', 'Graph', 'Tree (set theory)', 'Pathwidth', 'Line graph', 'Mathematical analysis']\n",
      "- ['Computer science', 'Semantic Web', 'Social Semantic Web', 'Semantic Web Stack', 'Semantics (computer science)', 'Semantic analytics', 'World Wide Web', 'Data Web', 'Web standards', 'Information retrieval', 'Semantic computing', 'The Internet', 'Web service', 'Programming language']\n",
      "- ['Computer science', 'Transparency (behavior)', 'Blockchain', 'Documentation', 'Key (lock)', 'Smart contract', 'Supply chain', 'Intermediary', 'Computer security', 'Software engineering', 'Business', 'Operating system', 'Finance', 'Marketing']\n",
      "- ['Computer science', 'Segmentation', 'Artificial intelligence', 'Pixel', 'Bottleneck', 'Classifier (UML)', 'Object detection', 'Image segmentation', 'Object (grammar)', 'Data mining', 'Pattern recognition (psychology)', 'Computer vision', 'Embedded system']\n",
      "\n",
      "Average abstract length (chars): 1137.6671111111111\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"works_ready.csv\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "print(\"\\nMissing abstracts:\", df['abstract_en'].isna().sum())\n",
    "print(\"Missing concepts:\", df['concepts'].isna().sum())\n",
    "print(\"Missing DOIs:\", df['doi'].isna().sum())\n",
    "\n",
    "print(\"\\nSample entries:\")\n",
    "print(df[['title', 'concepts', 'abstract_en']].head(3))\n",
    "\n",
    "# check how many rows are actually usable for retrieval\n",
    "usable = df[(df['abstract_en'].str.len() > 50) | (df['concepts'].notna())]\n",
    "print(f\"\\nUsable entries: {len(usable)} / {len(df)} ({len(usable)/len(df)*100:.1f}%)\")\n",
    "\n",
    "sample_concepts = df['concepts'].dropna().sample(5, random_state=42).tolist()\n",
    "print(\"\\nSample concept lists:\")\n",
    "for c in sample_concepts:\n",
    "    print(\"-\", c)\n",
    "\n",
    "\n",
    "print(\"\\nAverage abstract length (chars):\", df['abstract_en'].dropna().apply(len).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ['Computer science', 'Decision tree', 'Artific...\n",
      "1    ['Computer science', 'Residual', 'Regression',...\n",
      "2    ['Computer science', 'Point cloud', 'Spike (so...\n",
      "Name: concepts, dtype: object\n",
      "<class 'str'>\n",
      "['Computer science', 'Decision tree', 'Artificial intelligence', 'Machine learning', 'Decision tree learning', 'Tree (set theory)', 'Mathematics', 'Mathematical analysis']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"works_ready.csv\")\n",
    "\n",
    "print(df['concepts'].head(3))\n",
    "print(type(df['concepts'].iloc[0]))  \n",
    "\n",
    "# parse stringified lists\n",
    "def safe_parse_list(x):\n",
    "    if isinstance(x, str) and x.startswith('['):\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except:\n",
    "            return [x]\n",
    "    return x if isinstance(x, list) else [x] if pd.notna(x) else []\n",
    "\n",
    "df['concepts'] = df['concepts'].apply(safe_parse_list)\n",
    "df['concepts_norm'] = df['concepts_norm'].apply(safe_parse_list)\n",
    "\n",
    "print(df['concepts'].iloc[0])\n",
    "print(type(df['concepts'].iloc[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).replace(\"\\\\n\", \" \").replace(\"\\\\r\", \" \")\n",
    "    s = s.replace(\"  \", \" \").strip()\n",
    "    return s\n",
    "\n",
    "for col in ['title', 'abstract_en', 'abstract_de']:\n",
    "    df[col] = df[col].apply(clean_text)\n",
    "\n",
    "df = df.drop(columns=[\"orgunit\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"works_final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5814, 15)\n",
      "Columns: ['title', 'pub_type', 'date_issued', 'authors', 'doi', 'publisher', 'abstract_en', 'abstract_de', 'pdf_paths', 'pdf_count', 'openalex_id', 'concepts', 'cited_by_count', 'referenced_works_count', 'concepts_norm']\n",
      "\n",
      "Missing abstracts: 1314\n",
      "Missing concepts: 0\n",
      "Missing DOIs: 1699\n",
      "\n",
      "Example row:\n",
      "title          Unplugged Decision Tree Learning  A Learning A...\n",
      "concepts       [Computer science, Decision tree, Artificial i...\n",
      "abstract_en    Artificial intelligence (AI) is now deeply ing...\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Average abstract length (chars): 1137.6671111111111\n",
      "Average concept count: 10.438080495356036\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"works_final.csv\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "print(\"\\nMissing abstracts:\", df['abstract_en'].isna().sum())\n",
    "print(\"Missing concepts:\", df['concepts'].isna().sum())\n",
    "print(\"Missing DOIs:\", df['doi'].isna().sum())\n",
    "\n",
    "# verify that concepts are stored as lists, not strings\n",
    "def check_and_parse(x):\n",
    "    if isinstance(x, str) and x.startswith('['):\n",
    "        try: return ast.literal_eval(x)\n",
    "        except: return [x]\n",
    "    return x if isinstance(x, list) else [x] if pd.notna(x) else []\n",
    "\n",
    "df['concepts'] = df['concepts'].apply(check_and_parse)\n",
    "\n",
    "print(\"\\nExample row:\")\n",
    "print(df[['title','concepts','abstract_en']].iloc[0])\n",
    "\n",
    "print(\"\\nAverage abstract length (chars):\", df['abstract_en'].dropna().apply(len).mean())\n",
    "print(\"Average concept count:\", df['concepts'].apply(len).mean())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
